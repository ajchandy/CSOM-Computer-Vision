{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "In this tutorial, we shall improve on the exisiting classifier but taking the Transfer Learning approach.\n",
    "\n",
    "We shall use the <b>VGG16 CNN Architecture from Keras Framework pre-trained on ImageNet Dataset</b>.\n",
    "\n",
    "We shall follow the similar steps as before with a few changes in defining the model:<br>\n",
    "    1. Load the Data CIFAR10<br>\n",
    "    2. Load the pre-trained VGG16 model from Keras and Freeze the first few layers<br>\n",
    "    3. Add some end layers to cater for Classifying 10 Classes as in CIFAR10<br>\n",
    "    4. Train the model<br>\n",
    "    5. Evaluate the model on Test set<br>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Mention the Class Name List\n",
    "class_list = ['airplane','automobile','bird','cat','deer','dog',\n",
    "              'frog','horse','ship','truck']\n",
    "\n",
    "# # Convert a one-hot vector for the test-labels\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=len(class_list))\n",
    "\n",
    "\n",
    "# # Split the test set to Validation & Test set\n",
    "num_test_samples = x_test.shape[0]\n",
    "x_val, y_val = x_test[0:num_test_samples//2,:,:], y_test[0:num_test_samples//2]\n",
    "x_test, y_test = x_test[num_test_samples//2:,:,:], y_test[num_test_samples//2:]\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=len(class_list))\n",
    "\n",
    "# Create DATA GENERARTOR with data augmentation\n",
    "train_data_gen = ImageDataGenerator(rescale=1.0/255,horizontal_flip=False)\n",
    "train_data_gen.fit(x_train)\n",
    "train_generator = train_data_gen.flow(x_train, y_train, batch_size=32)\n",
    "\n",
    "val_data_gen = ImageDataGenerator(rescale=1.0/255,horizontal_flip=False)\n",
    "val_data_gen.fit(x_val)\n",
    "val_generator = val_data_gen.flow(x_val, y_val, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained model we are using here is the VGG16 model which has a total of 16 layers including the fully-connected layer. This model is pre-trained on the huge ImageNet Dataset (over 14M Images)\n",
    "\n",
    "We are going to Freeze the layers until layer `block3_pool` and add few layers of our own to retrain on the CIFAR10 training set. \n",
    "\n",
    "For using other base models - [Check this page](https://keras.io/applications/). Base Models can be swapped with any of the ones present on the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications import vgg16 as vgg\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "# Get the pre-trained model\n",
    "base_model = vgg.VGG16(weights='imagenet',\n",
    "                          include_top=False,\n",
    "                          input_shape=(32,32,3))\n",
    "\n",
    "# # Visualize the base_model and check the layer name to 'chop at'\n",
    "# base_model.summary()\n",
    "\n",
    "# Get the Last output from the base model from last layer\n",
    "last_output = base_model.get_layer('block3_pool').output\n",
    "\n",
    "# Add new Layers\n",
    "                                        # globalavg\n",
    "                                        # bn\n",
    "                                        # Dense + Relu\n",
    "                                        # Dense + Relu\n",
    "                                        # Dense + Softmax\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=base_model.input, outputs=pred)\n",
    "\n",
    "# Freeze layers of Base Model from getting Trained again. \n",
    "# The weights in these layers are not affected by BackPropagation\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "# Compile the Model with the Loss function, Optimizer and Accuracy Metric\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "\n",
    "# Visualize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model using Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the Image Generator\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=50000//32,\n",
    "                   validation_data=val_generator,\n",
    "                   validation_steps=5000//32,\n",
    "                   epochs=10,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Set\n",
    "y_pred = np.argmax(model.predict(x_test), axis=-1).reshape(5000,1)   #^\n",
    "\n",
    "acc = np.sum(y_test == y_pred) / y_test.shape[0]\n",
    "# Print Accuracy\n",
    "print(\"Test Accuracy :{}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pdb\n",
    "# UTILS FOR VISUALIZATION\n",
    "def plot_predictions(model,dataset,\n",
    "                    dataset_labels,label_dict,\n",
    "                    batch_size,grid_height=4,grid_width=4):\n",
    "    if model:\n",
    "        f, ax = plt.subplots(grid_width, grid_height)\n",
    "        f.set_size_inches(12, 12)\n",
    "       \n",
    "        random_batch_indx = np.random.permutation(np.arange(0,len(dataset)))[:batch_size]\n",
    "       \n",
    "        img_idx = 0\n",
    "        for i in range(0, grid_width):\n",
    "            for j in range(0, grid_height):\n",
    "                actual_label = label_dict.get(dataset_labels[random_batch_indx[img_idx]].argmax())\n",
    "                       \n",
    "                # make prediction and find score\n",
    "                prediction = model.predict(dataset[random_batch_indx[img_idx]].reshape(1,32,32,3))[0]\n",
    "                preds = [label_dict[idx] for idx in np.argsort(prediction)[::-1][:1]]\n",
    "                confs_ = np.sort(prediction)[::-1][:1]\n",
    "                ax[i][j].axis('off')\n",
    "                ax[i][j].set_title('Actual:'+actual_label+\\\n",
    "                                    '\\nPredicted:'+preds[0] + \\\n",
    "                                    '(' +str(round(confs_[0],2)) + ')')\n",
    "                ax[i][j].imshow(dataset[random_batch_indx[img_idx]])\n",
    "                img_idx += 1\n",
    "\n",
    "        plt.subplots_adjust(left=0, bottom=0, right=1,top=1, wspace=0.4, hspace=0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VISUALIZE ON A BATCH SIZE OF IMAGES\n",
    "plot_predictions(model=model,\n",
    "                 dataset=(x_test/255.),\n",
    "                 dataset_labels=keras.utils.to_categorical(y_test,num_classes=10),\n",
    "                 label_dict={class_list.index(i) : i for i in class_list},\n",
    "                  batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
