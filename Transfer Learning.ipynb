{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "In this tutorial, we shall improve on the exisiting classifier but taking the Transfer Learning approach.\n",
    "\n",
    "We shall use the <b>VGG16 CNN Architecture from Keras Framework pre-trained on ImageNet Dataset</b>.\n",
    "\n",
    "We shall follow the similar steps as before with a few changes in defining the model:\n",
    "    1. Load the Data CIFAR10\n",
    "    2. Load the pre-trained VGG16 model from Keras and Freeze the first few layers\n",
    "    3. Add some end layers to cater for Classifying 10 Classes as in CIFAR10\n",
    "    4. Train the model\n",
    "    5. Evaluate the model on Test set\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Mention the Class Name List\n",
    "class_list = ['airplane','automobile','bird','cat','deer','dog',\n",
    "              'frog','horse','ship','truck']\n",
    "\n",
    "# # Convert a one-hot vector for the test-labels\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=len(class_list))\n",
    "\n",
    "\n",
    "# # Split the test set to Validation & Test set\n",
    "num_test_samples = x_test.shape[0]\n",
    "x_val, y_val = x_test[0:num_test_samples//2,:,:], y_test[0:num_test_samples//2]\n",
    "x_test, y_test = x_test[num_test_samples//2:,:,:], y_test[num_test_samples//2:]\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=len(class_list))\n",
    "\n",
    "# Create DATA GENERARTOR with data augmentation\n",
    "train_data_gen = ImageDataGenerator(rescale=1.0/255,horizontal_flip=False)\n",
    "train_data_gen.fit(x_train)\n",
    "train_generator = train_data_gen.flow(x_train, y_train, batch_size=32)\n",
    "\n",
    "val_data_gen = ImageDataGenerator(rescale=1.0/255,horizontal_flip=False)\n",
    "val_data_gen.fit(x_val)\n",
    "val_generator = val_data_gen.flow(x_val, y_val, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications import vgg16 as vgg\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "# Get the pre-trained model\n",
    "vgg_base_model = vgg.VGG16(weights='imagenet',\n",
    "                          include_top=False,\n",
    "                          input_shape=(32,32,3))\n",
    "\n",
    "# Get the Last output from the base model from last layer\n",
    "last_output = vgg_base_model.get_layer('block3_pool').output\n",
    "\n",
    "# Add new Layers\n",
    "x = GlobalAveragePooling2D()(last_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu', name='d1')(x)\n",
    "x = Dense(256, activation='relu', name='d2')(x)\n",
    "\n",
    "pred = Dense(len(class_list),activation='softmax')(x)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=vgg_base_model.input, outputs=pred)\n",
    "\n",
    "# Freeze layers of Base Model\n",
    "for layer in vgg_base_model.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "# Compile the Model with the Loss function, Optimizer and Accuracy Metric\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "\n",
    "# Visualize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train = shuffle(x_train, y_train)\n",
    "# Train the model\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=50000//32,\n",
    "                   validation_data=val_generator,\n",
    "                   validation_steps=5000//32,\n",
    "                   epochs=10,\n",
    "                   verbose=1)\n",
    "# model.fit(x_train, y_train, validation_data=(x_val,y_val), epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Set\n",
    "y_pred = np.argmax(model.predict(x_test), axis=-1).reshape(5000,1)\n",
    "\n",
    "acc = np.sum(y_test == y_pred) / y_test.shape[0]\n",
    "# Print Accuracy\n",
    "print(\"Test Accuracy :{}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
