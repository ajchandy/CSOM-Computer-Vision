{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we shall train a model for classification on dataset using our own network, and then we shall evaluate how good/bad it is compared to the the one trained using transfer learning.\n",
    "\n",
    "We use the famous CIFAR10 dataset readily avaliable from one of the frameworks. \n",
    "\n",
    "We shall follow the following steps: \n",
    "1. Load the Data (already split into train and test)\n",
    "2. Define a Convolutional Neural Network to train a Classification Problem for classifying into 10 classes from the image input\n",
    "3. Train a model using the training set, and created validation set\n",
    "4. Evluate the model on test set\n",
    "5. Repeat a similar approach for Tranfer Learning using a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Mention the Class Name List\n",
    "class_list = ['airplane','automobile','bird','cat','deer','dog',\n",
    "              'frog','horse','ship','truck']\n",
    "\n",
    "# # Convert a one-hot vector for the test-labels\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=len(class_list))\n",
    "\n",
    "\n",
    "# # Split the test set to Validation & Test set\n",
    "num_test_samples = x_test.shape[0]\n",
    "x_val, y_val = x_test[0:num_test_samples//2,:,:], y_test[0:num_test_samples//2]\n",
    "x_test, y_test = x_test[num_test_samples//2:,:,:], y_test[num_test_samples//2:]\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=len(class_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data \n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0,60000)\n",
    "class_fig = class_list[np.argmax(y_train[num])]\n",
    "\n",
    "plt.imshow(x_train[num].reshape(32,32))\n",
    "print(\"Class Name :{}\".format(class_fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Conv2D, Activation, Dense, Flatten, MaxPooling2D\n",
    "\n",
    "# Writing the model\n",
    "model = Sequential(name='CIFAR-Classifier')\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=3, strides=2,padding=\"same\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3), strides=(2,2),padding=\"same\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3), strides=(2,2),padding=\"same\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax',use_bias=True))\n",
    "\n",
    "# Compile the Model with the Loss function, Optimizer and Accuracy Metric\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Check the Architecture\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_val,y_val), epochs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Set\n",
    "y_pred = model.predict_classes(x_test)\n",
    "acc = np.sum(y_test == y_pred) / y_test.shape[0]\n",
    "# Print Accuracy\n",
    "print(\"Test Accuracy :{}\".format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
